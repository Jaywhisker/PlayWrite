{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from googleapiclient.discovery import build\n",
    "import re\n",
    "from isodate import parse_duration\n",
    "import subprocess\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from spleeter.separator import Separator\n",
    "import shutil \n",
    "import cv2\n",
    "import torch\n",
    "from transformers import  AutoProcessor, AutoModelForVision2Seq, AutoTokenizer, AutoModelForCausalLM, TextStreamer, GenerationConfig\n",
    "import csv\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "ckpt = \"microsoft/kosmos-2-patch14-224\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(ckpt).to(\"cuda\")\n",
    "processor = AutoProcessor.from_pretrained(ckpt)\n",
    "\n",
    "\n",
    "sys.path.append(r'D:\\video_extraction\\inaSpeechSegmenter')\n",
    "from inaSpeechSegmenter import Segmenter\n",
    "from inaSpeechSegmenter.export_funcs import seg2csv, seg2textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = 'insert api key here'\n",
    "api_key = ''\n",
    "hg_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_videos(api_key, search_term, limit):\n",
    "    # Initialize the YouTube API client\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_urls = []\n",
    "    page_token = None\n",
    "    while len(video_urls) < limit:\n",
    "        # Adjust the search limit based on remaining needed videos\n",
    "        search_limit = min(limit - len(video_urls), 50)  # API max is 50 for a single request\n",
    "\n",
    "        # Search for videos matching the term with pagination\n",
    "        search_response = youtube.search().list(\n",
    "            q=search_term,\n",
    "            part='id,snippet',\n",
    "            maxResults=search_limit,\n",
    "            type='video',\n",
    "            #videoDuration='medium',  # Filters videos approximately between 4-20 minutes\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "\n",
    "        if not video_ids:\n",
    "            break  # Exit if no more videos are found\n",
    "\n",
    "        # Fetch details for each video to filter by precise duration\n",
    "        videos_response = youtube.videos().list(\n",
    "            part='contentDetails',\n",
    "            id=','.join(video_ids)\n",
    "        ).execute()\n",
    "\n",
    "        for item in videos_response['items']:\n",
    "            duration = parse_duration(item['contentDetails']['duration']).total_seconds()\n",
    "            if 240 <= duration <= 3600:  # 4 minutes to 30 minutes in seconds\n",
    "                video_urls.append(f\"https://www.youtube.com/watch?v={item['id']}\")\n",
    "                if len(video_urls) >= limit:\n",
    "                    break\n",
    "\n",
    "        page_token = search_response.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break  # Exit the loop if there are no more pages to fetch\n",
    "\n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video 30s clip downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(title):\n",
    "    # Replace spaces and special characters with underscores\n",
    "    # This is a basic example; you might need to extend it to cover more cases\n",
    "    return re.sub(r'[^\\w\\-_\\. ]', '_', title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_and_extract_random_clips(url, output_dir, number_of_clips=10, clip_length=30):\n",
    "    try:\n",
    "        # Ensure the output directory exists\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Define preferences\n",
    "        format_preference = \"18\"  # yt-dlp resolution\n",
    "\n",
    "        # Fetch the video title for naming\n",
    "        command_get_title = [\"yt-dlp\", \"--get-title\", url]\n",
    "        result_title = subprocess.run(command_get_title, capture_output=True, text=True, check=True, encoding='utf-8')\n",
    "\n",
    "        title = result_title.stdout.strip()\n",
    "        safe_title = sanitize_filename(title)\n",
    "        output_template = os.path.join(output_dir, f\"{safe_title}.%(ext)s\")\n",
    "        \n",
    "        # Download the video\n",
    "        print(\"Downloading video...\")\n",
    "        command_download = [\"yt-dlp\", \"-f\", format_preference, \"-o\", output_template, url]\n",
    "        subprocess.run(command_download, capture_output=True, text=True, check=True)\n",
    "\n",
    "        downloaded_filename = os.path.normpath(output_template.replace('%(ext)s', 'mp4'))\n",
    "\n",
    "        print(f\"Downloaded filename: {downloaded_filename}\")\n",
    "\n",
    "        if not os.path.exists(downloaded_filename):\n",
    "            raise FileNotFoundError(f\"Expected downloaded file not found: {downloaded_filename}\")\n",
    "\n",
    "        # Get video duration\n",
    "        command_duration = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", downloaded_filename]\n",
    "        result_duration = subprocess.run(command_duration, capture_output=True, text=True)\n",
    "        duration_seconds = float(result_duration.stdout.strip())\n",
    "\n",
    "        # Generate random start times\n",
    "        clip_paths = []\n",
    "        for i in range(number_of_clips):\n",
    "            start_time = random.randint(0, max(int(duration_seconds - clip_length), 0))\n",
    "            clip_filename = os.path.join(output_dir, f\"{safe_title}_clip_{i}.mp4\")\n",
    "\n",
    "            # Extract a 30s clip from the video\n",
    "            command_extract = [\"ffmpeg\", \"-ss\", str(start_time), \"-t\", str(clip_length), \"-i\", downloaded_filename, \"-c:v\", \"libx264\", \"-c:a\", \"aac\", clip_filename]\n",
    "            subprocess.run(command_extract, check=True, capture_output=True, text=True)\n",
    "            \n",
    "            clip_paths.append(clip_filename)\n",
    "\n",
    "        # Optionally, delete the original video file\n",
    "        os.remove(downloaded_filename)\n",
    "\n",
    "        # Return the list of clip filenames\n",
    "        return clip_paths\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred during subprocess execution: {e.stderr}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "music extract shiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_and_get_path(video_path, output_directory):\n",
    "    \"\"\"\n",
    "    Extracts music from a video file by separating it from vocals, replaces the original audio\n",
    "    of the video with the extracted music, and saves the edited version alongside the original.\n",
    "    Returns the path to the edited video and cleans up all temporary files and directories created during the process.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: The path to the video file.\n",
    "    - output_directory: The directory where the separated audio files will be temporarily stored.\n",
    "\n",
    "    Returns:\n",
    "    - Path to the edited video.\n",
    "    \"\"\"\n",
    "    # Ensure output_directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Step 1: Extract and separate audio\n",
    "    audio_output_path = os.path.join(output_directory, 'extracted_audio.wav')\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_output_path)\n",
    "    video.close()  # Close the clip to release the file handle\n",
    "\n",
    "    separator = Separator('spleeter:2stems')\n",
    "    separator.separate_to_file(audio_output_path, output_directory)\n",
    "    accompaniment_file_path = os.path.join(output_directory, 'extracted_audio', 'accompaniment.wav')\n",
    "\n",
    "    # Step 2: Replace audio in the video\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    accompaniment_audio_clip = AudioFileClip(accompaniment_file_path)\n",
    "    video_with_new_audio = video_clip.set_audio(accompaniment_audio_clip)\n",
    "    \n",
    "    edited_video_path = video_path.rsplit(\".\", 1)[0] + \"_edited.\" + video_path.split(\".\")[-1]\n",
    "    video_with_new_audio.write_videofile(edited_video_path, codec='libx264', audio_codec='aac')\n",
    "    video_clip.close()\n",
    "    accompaniment_audio_clip.close()\n",
    "    video_with_new_audio.close()\n",
    "\n",
    "    # Step 4: Clean up temporary files and directories\n",
    "    os.remove(audio_output_path)\n",
    "    shutil.rmtree(os.path.join(output_directory, 'extracted_audio'), ignore_errors=True)\n",
    "    os.remove(video_path)\n",
    "    return edited_video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect if 80% is audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_delete_clip_if_not_enough_music(media):\n",
    "    # Assuming the Segmenter and seg2csv setup is correct and in place\n",
    "\n",
    "    # Placeholder for your existing code that generates the CSV\n",
    "    # Simulating the CSV creation to fit the function's structure\n",
    "    seg = Segmenter()\n",
    "    segmentation = seg(media)\n",
    "    seg2csv(segmentation, 'myseg.csv')\n",
    "    \n",
    "    try:\n",
    "        # Assuming the first row could be headers that are misinterpreted\n",
    "        segmentation_df = pd.read_csv('myseg.csv', sep='\\t', names=['labels', 'start', 'stop'], skiprows=1)\n",
    "    except ValueError:\n",
    "        print(\"Error reading the segmentation CSV. Please check the format.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        segmentation_df['start'] = segmentation_df['start'].astype(float)\n",
    "        segmentation_df['stop'] = segmentation_df['stop'].astype(float)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting start/stop times to float: {e}\")\n",
    "        return None\n",
    "\n",
    "    total_music_duration = segmentation_df[segmentation_df['labels'] == 'music']['stop'].sum() - \\\n",
    "                           segmentation_df[segmentation_df['labels'] == 'music']['start'].sum()\n",
    "\n",
    "    if total_music_duration < 25:\n",
    "        try:\n",
    "            os.remove(media)\n",
    "            print(f\"Deleted {media} due to insufficient music duration.\")\n",
    "            return None\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting file {media}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"{media} contains enough music. It will not be deleted.\")\n",
    "        return media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screenshots(video_path):\n",
    "    \"\"\"\n",
    "    Captures screenshots from a video at specified times and returns a dictionary with custom keys for each path.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: Path to the video file.\n",
    "    - times: List of times in seconds at which to capture the screenshots.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with keys like 'path1', 'path2', etc., pointing to the file paths of the captured screenshots.\n",
    "    \"\"\"\n",
    "    # List of times in seconds at which to capture the screenshots.\n",
    "    times = [5, 10, 15, 20, 25]\n",
    "    \n",
    "    # Initialize a dictionary to hold the paths of the screenshots with custom keys.\n",
    "    screenshots_paths = {}\n",
    "\n",
    "    # Load the video.\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if video opened successfully.\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return screenshots_paths\n",
    "\n",
    "    # Get video FPS (frames per second) to calculate the frame number.\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # The directory where screenshots will be saved.\n",
    "    save_directory = \"D:\\\\video_extraction\\\\video\\\\360p\"\n",
    "\n",
    "    # Iterate over the specified times, using enumerate to get both index and time.\n",
    "    for index, time in enumerate(times, start=1):\n",
    "        # Calculate the frame number.\n",
    "        frame_number = int(time * fps)\n",
    "\n",
    "        # Set video position to the specific frame.\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        # Read the frame.\n",
    "        success, frame = video.read()\n",
    "\n",
    "        # Check if the frame was grabbed successfully.\n",
    "        if success:\n",
    "            # Define the file path for the screenshot, including the save directory.\n",
    "            file_path = f\"{save_directory}\\\\screenshot_{time}s.jpg\"\n",
    "\n",
    "            # Save the frame as an image file.\n",
    "            cv2.imwrite(file_path, frame)\n",
    "\n",
    "\n",
    "            # Use a custom key for each path.\n",
    "            key = f\"path{index}\"\n",
    "\n",
    "            # Add the key and file path to the dictionary.\n",
    "            screenshots_paths[key] = file_path\n",
    "        else:\n",
    "            print(f\"Error: Could not capture screenshot at {time}s\")\n",
    "\n",
    "    # Release the video capture object.\n",
    "    video.release()\n",
    "\n",
    "    # Return the dictionary of screenshot paths.\n",
    "    return screenshots_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(image_path, text_input=\"Detailed\"):\n",
    "    image_input = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    if text_input.lower() == \"brief\":\n",
    "        text_input = \"<grounding>An image of\"\n",
    "    elif text_input.lower() == \"detailed\":\n",
    "        text_input = \"<grounding>Describe this image in detail:\"\n",
    "    else:\n",
    "        text_input = f\"<grounding>{text_input}\"\n",
    "\n",
    "    inputs = processor(text=text_input, images=image_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        image_embeds=None,\n",
    "        image_embeds_position_mask=inputs[\"image_embeds_position_mask\"],\n",
    "        use_cache=True,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    processed_text = processor.post_process_generation(generated_text)\n",
    "\n",
    "    actual_description = processed_text[0].replace(\"Describe this image in detail: \", \"\")\n",
    "\n",
    "    return actual_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    system_prompt = None\n",
    "    user_messages = []\n",
    "    model_replies = []\n",
    "\n",
    "    def __init__(self, system_prompt=None):\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def add_user_message(self, message: str, return_prompt=True):\n",
    "        self.user_messages.append(message)\n",
    "        if return_prompt:\n",
    "            return self.build_prompt()\n",
    "\n",
    "    def add_model_reply(self, reply: str, includes_history=True, return_reply=True):\n",
    "        reply_ = reply.replace(self.build_prompt(), \"\") if includes_history else reply\n",
    "        self.model_replies.append(reply_)\n",
    "        if len(self.user_messages) != len(self.model_replies):\n",
    "            raise ValueError(\n",
    "                \"Number of user messages does not equal number of system replies.\"\n",
    "            )\n",
    "        if return_reply:\n",
    "            return reply_\n",
    "\n",
    "    def get_user_messages(self, strip=True):\n",
    "        return [x.strip() for x in self.user_messages] if strip else self.user_messages\n",
    "\n",
    "    def get_model_replies(self, strip=True):\n",
    "        return [x.strip() for x in self.model_replies] if strip else self.model_replies\n",
    "\n",
    "    def clear_chat_history(self):\n",
    "        self.user_messages.clear()\n",
    "        self.model_replies.clear()\n",
    "\n",
    "    def build_prompt(self):\n",
    "        if self.user_messages == [] and self.model_replies == []:\n",
    "            return f\"<s>[INST] <<SYS>>\\n{self.system_prompt}\\n<</SYS>> [/INST]</s>\"\n",
    "        \n",
    "        elif len(self.user_messages) != len(self.model_replies) + 1:\n",
    "            raise ValueError(\n",
    "                \"Error: Expected len(user_messages) = len(model_replies) + 1. Add a new user message!\"\n",
    "            )\n",
    "\n",
    "        if self.system_prompt is not None:\n",
    "            SYS = f\"[INST] <<SYS>>\\n{self.system_prompt}\\n<</SYS>>\"\n",
    "        else:\n",
    "            SYS = \"\"\n",
    "\n",
    "        CONVO = \"\"\n",
    "        SYS = \"<s>\" + SYS\n",
    "        for i in range(len(self.user_messages) - 1):\n",
    "            user_message, model_reply = self.user_messages[i], self.model_replies[i]\n",
    "            conversation_ = f\"{user_message} [/INST] {model_reply} </s>\"\n",
    "            if i != 0:\n",
    "                conversation_ = \"[INST] \" + conversation_\n",
    "            CONVO += conversation_\n",
    "\n",
    "        CONVO += f\"[INST] {self.user_messages[-1]} [/INST]\"\n",
    "\n",
    "        return SYS + CONVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" \n",
    "llama_model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-chat-hf', token=hg_key, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-chat-hf', token=hg_key)\n",
    "print(f\"Model running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_llama(context_prompt, llama_tokenizer, llama_model):\n",
    "    # Initialize the prompt generator with the given context\n",
    "    prompt = PromptTemplate(context_prompt)\n",
    "    true_prompt = prompt.build_prompt()\n",
    "\n",
    "    config = GenerationConfig(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample= True,\n",
    "        top_k= 10,\n",
    "        num_return_sequences= 1,\n",
    "        return_full_text= False,\n",
    "        temperature= 0.1,\n",
    "    )\n",
    "\n",
    "    text_stream = TextStreamer(llama_tokenizer, skip_prompt=True)\n",
    "    encoded_input = llama_tokenizer.encode(true_prompt, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    results = llama_model.generate(encoded_input, generation_config=config, streamer=text_stream)\n",
    "    decoded_output = llama_tokenizer.decode(results[0], skip_special_tokens=True)\n",
    "    response = decoded_output.split(\"[/INST]\")[-1].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(base_path, file_name, path, caption):\n",
    "    \"\"\"\n",
    "    Appends a single video path and caption to a CSV file.\n",
    "    \n",
    "    :param base_path: The directory where the CSV file will be saved.\n",
    "    :param file_name: The name of the CSV file.\n",
    "    :param path: The video path to append.\n",
    "    :param caption: The caption to append.\n",
    "    \"\"\"\n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    # Construct the full file path for the CSV\n",
    "    csv_file_path = os.path.join(base_path, file_name)\n",
    "\n",
    "    # Open the CSV file for appending. Use 'a' mode.\n",
    "    with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Check if the file is empty to decide on writing headers\n",
    "        file.seek(0, os.SEEK_END)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(['Video Path', 'Caption'])\n",
    "        \n",
    "        # Append the video path and caption\n",
    "        writer.writerow([path, caption])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(api_key):\n",
    "    video_urls = fetch_videos(api_key,\"no commentary walkthrough\", 50)\n",
    "    for url in video_urls:\n",
    "        clip_file_path = download_video_and_extract_random_clips(url, output_dir=\"D:\\\\video_extraction\\\\video\\\\360p\")\n",
    "        for clip in clip_file_path:\n",
    "            file_path = check_and_delete_clip_if_not_enough_music(clip)\n",
    "            if file_path is not None:\n",
    "                screenshot_paths = capture_screenshots(file_path)\n",
    "                captions = []\n",
    "                for screenshot in screenshot_paths.values():\n",
    "                    captions.append(generate_predictions(screenshot))\n",
    "                    os.remove(screenshot)\n",
    "                context_prompt=f\"\"\"context={captions[0]},{captions[1]},{captions[2]},{captions[3]},{captions[4]}. \n",
    "            imagine you are writing a description of a video. You are capturing the emotions caused by the environment and atmosphere. You should write a 30 word paragraph that takes the 5 context and summarise all of them into that one paragraph. Talk about the environment, the vibes and the emotions. Immediately starts describing and do not mention the source. I will give you example prompts, follow their formatting but not the content. Give me just the paragraph and nothing else. \n",
    "            example prompts:\n",
    "            A small rural village. The atmosphere is peaceful, with citizens doing their daily tasks. However, there is an underlying tension in the air, like something is about to go down. The overall emotion of the video is one of suspense and intrigue.\n",
    "            \"\"\"\n",
    "                generated_text = generate_response_with_llama(context_prompt, llama_tokenizer, llama_model) \n",
    "                save_to_csv('D:\\\\video_extraction\\\\video\\\\360p', 'videos_and_captions.csv', file_path, generated_text[2:])\n",
    "\n",
    "                \n",
    "            else:\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
