{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to generate the text-to-game music dataset\n",
    "Pipeline:\n",
    "1. Scrape YouTube Videos with youtube API key\n",
    "2. Crop 30s videos and check for music (keep videos with >25s of music)\n",
    "3. Screenshot videos and caption them with kosmos-2\n",
    "4. Push captions to Llama2-7b to retrieve text prompt\n",
    "\n",
    "\n",
    "Please ensure you have the following:\n",
    "1. A hugging face access key from an accurate that has granted access to meta llama repository. Get access here: https://huggingface.co/meta-llama/Llama-2-7b\n",
    "\n",
    "2. A youtube API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_access = 'FILL IN YOUR ACCESS CODE HERE'\n",
    "yt_API = 'FILL IN YOUR ACCESS CODE HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Please run the following cell to setup inaSpeechSegmenter\n",
    "\n",
    "By default, it will be downloaded into the same folder as the notebook\n",
    "\n",
    "If you would like to change the folder directory, please update the folder when doing the imports in the later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def setup_inaSpeechSegmenter(directory:str=''):\n",
    "    \"\"\"\n",
    "    Function to download inaSpeechSegmenter. This command make uses of os to run terminal commands.\n",
    "    Alternatively, please following the instruction process here: https://github.com/ina-foss/inaSpeechSegmenter\n",
    "\n",
    "    Args:\n",
    "        directory (str, optional): directory to the inaSpeechSegmenter. Defaults to ''.\n",
    "    \n",
    "    Returns:\n",
    "        0 for success and 1 for failure\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory) \n",
    "        print(\"Setup directory not found, directory created\")\n",
    "\n",
    "    try:\n",
    "        if directory == '':\n",
    "            directory = os.getcwd()\n",
    "        \n",
    "        os.chdir(directory)\n",
    "        os.system(\"git clone https://github.com/ina-foss/inaSpeechSegmenter.git\")\n",
    "        os.chdir(\"inaSpeechSegmenter\")\n",
    "        os.system(\"pip install .\")\n",
    "        os.system(\"python setup.py test\")\n",
    "        return 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download inaSpeechSegmenter, error: {e}\")\n",
    "        return 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_inaSpeechSegmenter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating text-to-game music dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import shutil \n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from isodate import parse_duration\n",
    "from transformers import  AutoProcessor, AutoModelForVision2Seq, AutoTokenizer, AutoModelForCausalLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing inaSpeechSegmenter\n",
    "\n",
    "#to import, you need to be in the inaSpeechSegmenter folder, PLEASE update the directory respectively\n",
    "current_path = os.getcwd()\n",
    "if current_path[-18:] != 'inaSpeechSegmenter':\n",
    "    os.chdir('inaSpeechSegmenter') #UPDATE YOUR PATH HERE\n",
    "\n",
    "from inaSpeechSegmenter import Segmenter\n",
    "from inaSpeechSegmenter.export_funcs import seg2csv, seg2textgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Youtube Links Fetcher and Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_videos(api_key:str, search_term:str=\"no commentary walkthrough\", video_duration:list=[240, 3600], limit:int=10):\n",
    "    \"\"\"\n",
    "    Function to retrieve different youtube links from search term\n",
    "\n",
    "    Args:\n",
    "        api_key (str): youtube api key\n",
    "        search_term (str, optional): youtube search term. Defaults to \"no commentary walkthrough\"\n",
    "        video_duration (list, optional): accepted videos will be within this duration. Defaults to [240,3600] -> 4 to 30 minutes\n",
    "        limit (int, optional): maximum num of links. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list of youtube url links\n",
    "    \"\"\"\n",
    "    # Initialize the YouTube API client\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_urls = []\n",
    "    page_token = None\n",
    "\n",
    "    while len(video_urls) < limit:\n",
    "        # Adjust the search limit based on remaining needed videos\n",
    "        search_limit = min(limit - len(video_urls), 50)  # API max is 50 for a single request\n",
    "\n",
    "        # Search for videos matching the term with pagination\n",
    "        search_response = youtube.search().list(\n",
    "            q=search_term,\n",
    "            part='id,snippet',\n",
    "            maxResults=search_limit,\n",
    "            type='video',\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "\n",
    "        if not video_ids:\n",
    "            print(\"No more videos found, exiting\")\n",
    "            break  # Exit if no more videos are found\n",
    "\n",
    "        # Fetch details for each video to filter by precise duration\n",
    "        videos_response = youtube.videos().list(\n",
    "            part='contentDetails',\n",
    "            id=','.join(video_ids)\n",
    "        ).execute()\n",
    "\n",
    "        for item in videos_response['items']:\n",
    "            duration = parse_duration(item['contentDetails']['duration']).total_seconds()\n",
    "            if video_duration[0] <= duration <= video_duration[1]:  # checking video duration\n",
    "                video_urls.append(f\"https://www.youtube.com/watch?v={item['id']}\")\n",
    "                if len(video_urls) >= limit:\n",
    "                    break\n",
    "\n",
    "        page_token = search_response.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break  # Exit the loop if there are no more pages to fetch\n",
    "\n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract_clips(url:str, \n",
    "                            output_dir:str, \n",
    "                            number_of_clips:int=10, \n",
    "                            clip_length:int=30):\n",
    "    \"\"\"\n",
    "    Function to download the video and randomly create clips\n",
    "    Note: Function uses os and subprocesses\n",
    "\n",
    "    Args:\n",
    "        url (str): youtube url link\n",
    "        output_dir (str): folder where the videos will go\n",
    "        number_of_clips (int, optional): number of clips to cut per video. Defaults to 10.\n",
    "        clip_length (int, optional): length of each clips in seconds. Defaults to 30.\n",
    "\n",
    "    Returns:\n",
    "        clip_paths (list): list of clip filenames else None if there is an error\n",
    "    \n",
    "    Raise:\n",
    "        FileNotFoundError: occurs if the downloaded video was unfound. Directory error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the output directory exists\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Define preferences\n",
    "        format_preference = \"18\"  # yt-dlp resolution\n",
    "\n",
    "        # Fetch the video title for naming\n",
    "        command_get_title = [\"yt-dlp\", \"--get-title\", url]\n",
    "        result_title = subprocess.run(command_get_title, capture_output=True, text=True, check=True, encoding='utf-8')\n",
    "\n",
    "        title = result_title.stdout.strip()\n",
    "        clean_title = re.sub(r'[^\\w\\-_\\. ]', '_', title)\n",
    "        output_template = os.path.join(output_dir, f\"{clean_title}.%(ext)s\")\n",
    "        \n",
    "        # Download the video\n",
    "        print(\"Downloading video...\")\n",
    "        command_download = [\"yt-dlp\", \"-f\", format_preference, \"-o\", output_template, url]\n",
    "        subprocess.run(command_download, capture_output=True, text=True, check=True)\n",
    "\n",
    "        downloaded_filename = os.path.normpath(output_template.replace('%(ext)s', 'mp4'))\n",
    "\n",
    "        print(f\"Downloaded filename: {downloaded_filename}\")\n",
    "\n",
    "        if not os.path.exists(downloaded_filename):\n",
    "            raise FileNotFoundError(f\"Expected downloaded file not found: {downloaded_filename}\")\n",
    "\n",
    "        # Get video duration\n",
    "        command_duration = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", downloaded_filename]\n",
    "        result_duration = subprocess.run(command_duration, capture_output=True, text=True)\n",
    "        duration_seconds = float(result_duration.stdout.strip())\n",
    "\n",
    "        # Generate random start times\n",
    "        clip_paths = []\n",
    "        for i in range(number_of_clips):\n",
    "            start_time = random.randint(0, max(int(duration_seconds - clip_length), 0))\n",
    "            clip_filename = os.path.join(output_dir, f\"{clean_title}_clip_{i}.mp4\")\n",
    "\n",
    "            # Extract a 30s clip from the video\n",
    "            command_extract = [\"ffmpeg\", \"-ss\", str(start_time), \"-t\", str(clip_length), \"-i\", downloaded_filename, \"-c:v\", \"libx264\", \"-c:a\", \"aac\", clip_filename]\n",
    "            subprocess.run(command_extract, check=True, capture_output=True, text=True)\n",
    "            \n",
    "            clip_paths.append(clip_filename)\n",
    "\n",
    "        # Optionally, delete the original video file\n",
    "        os.remove(downloaded_filename)\n",
    "\n",
    "        # Return the list of clip filenames\n",
    "        return clip_paths\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred during subprocess execution: {e.stderr}.\\nSkipping Video\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\\nSkipping Video\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check video audio for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_music_length(media_path:str, csv_path:str='myseg.csv', music_length_threshold:int=25):\n",
    "    \"\"\"\n",
    "    Function to run Segmenter on the edited audio to check how much music is inside\n",
    "\n",
    "    Args:\n",
    "        media_path (str): path to video clip\n",
    "        csv_path (str, optional): path to where csv of music data will be stored. Defaults to myseg.csv\n",
    "        music_length_threshold (int, optional): threshold for how long music must be in seconds. Defaults to 25s\n",
    "\n",
    "    Returns:\n",
    "        media_path: path of the video clip if it passes the threshold, else None\n",
    "    \"\"\"\n",
    "    seg = Segmenter()\n",
    "    segmentation = seg(media_path)\n",
    "    seg2csv(segmentation, csv_path)\n",
    "    \n",
    "    try:\n",
    "        # Assuming the first row could be headers that are misinterpreted\n",
    "        segmentation_df = pd.read_csv(csv_path, sep='\\t', names=['labels', 'start', 'stop'], skiprows=1)\n",
    "    except ValueError:\n",
    "        print(\"Error reading the segmentation CSV. Please check the format.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        segmentation_df['start'] = segmentation_df['start'].astype(float)\n",
    "        segmentation_df['stop'] = segmentation_df['stop'].astype(float)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting start/stop times to float: {e}\")\n",
    "        return None\n",
    "\n",
    "    total_music_duration = segmentation_df[segmentation_df['labels'] == 'music']['stop'].sum() - \\\n",
    "                           segmentation_df[segmentation_df['labels'] == 'music']['start'].sum()\n",
    "\n",
    "    #delete video if music lower than threshold\n",
    "    if total_music_duration < music_length_threshold:\n",
    "        try:\n",
    "            os.remove(media_path)\n",
    "            print(f\"Deleted {media_path} due to insufficient music duration.\")\n",
    "            return None\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting file {media_path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"{media_path} contains enough music. It will not be deleted.\")\n",
    "        return media_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshot Videos and Caption Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screenshots(video_path:str, interval:list=[5,10,15,20,25]):\n",
    "    \"\"\"\n",
    "    Captures screenshots from a video at specified times and returns a dictionary with custom keys for each path.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        interval (list): List of times in seconds at which to capture the screenshots. Defaults to [5,10,15,20,25].\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with keys like 'path1', 'path2', etc., pointing to the file paths of the captured screenshots.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold the paths of the screenshots with custom keys.\n",
    "    screenshots_paths = {}\n",
    "\n",
    "    # Load the video.\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if video opened successfully.\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return screenshots_paths\n",
    "\n",
    "    # Get video FPS (frames per second) to calculate the frame number.\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # The directory where screenshots will be saved.\n",
    "    save_directory = \"D:\\\\video_extraction\\\\video\\\\360p\"\n",
    "\n",
    "    # Iterate over the specified times, using enumerate to get both index and time.\n",
    "    for index, time in enumerate(interval, start=1):\n",
    "        # Calculate the frame number.\n",
    "        frame_number = int(time * fps)\n",
    "\n",
    "        # Set video position to the specific frame.\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        # Read the frame.\n",
    "        success, frame = video.read()\n",
    "\n",
    "        # Check if the frame was grabbed successfully.\n",
    "        if success:\n",
    "            # Define the file path for the screenshot, including the save directory.\n",
    "            file_path = f\"{save_directory}/screenshot_{time}s.jpg\"\n",
    "\n",
    "            # Save the frame as an image file.\n",
    "            cv2.imwrite(file_path, frame)\n",
    "\n",
    "            # Use a custom key for each path.\n",
    "            key = f\"path{index}\"\n",
    "\n",
    "            # Add the key and file path to the dictionary.\n",
    "            screenshots_paths[key] = file_path\n",
    "        else:\n",
    "            print(f\"Error: Could not capture screenshot at {time}s\")\n",
    "\n",
    "    # Release the video capture object.\n",
    "    video.release()\n",
    "\n",
    "    # Return the dictionary of screenshot paths.\n",
    "    return screenshots_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_image(model:AutoModelForVision2Seq, processor:AutoProcessor, image_path:str, text_input:str=\"detailed\", device:str='cuda'):\n",
    "    \"\"\"\n",
    "    Function to caption screenshots \n",
    "\n",
    "    Args:\n",
    "        model (AutoModelForVision2Seq): model to caption image, by default it shld be Kosmos-2\n",
    "        processor (AutoProcessor): tokenizer model for model\n",
    "        image_path (str): path to image\n",
    "        text_input (str, optional): grounding prompts. Using brief, or detailed will use pre-defined prompts. Defaults to detailed\n",
    "        device (str, optional): cuda or cpu. Defaults to cuda\n",
    "\n",
    "    Returns:\n",
    "        captions (str): image caption\n",
    "    \"\"\"    \n",
    "    #read image\n",
    "    image_input = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    if text_input.lower() == \"brief\":\n",
    "        text_input = \"<grounding>An image of\"\n",
    "    elif text_input.lower() == \"detailed\":\n",
    "        text_input = \"<grounding>Describe this image in detail:\"\n",
    "    else:\n",
    "        text_input = f\"<grounding>{text_input}\"\n",
    "\n",
    "    inputs = processor(text=text_input, images=image_input, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    #caption image\n",
    "    generated_ids = model.generate(\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        image_embeds=None,\n",
    "        image_embeds_position_mask=inputs[\"image_embeds_position_mask\"],\n",
    "        use_cache=True,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    processed_text = processor.post_process_generation(generated_text)\n",
    "\n",
    "    caption = processed_text[0].replace(\"Describe this image in detail: \", \"\")\n",
    "\n",
    "    return caption\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    system_prompt = None\n",
    "    user_messages = []\n",
    "    model_replies = []\n",
    "\n",
    "    def __init__(self, system_prompt=None):\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def add_user_message(self, message: str, return_prompt=True):\n",
    "        self.user_messages.append(message)\n",
    "        if return_prompt:\n",
    "            return self.build_prompt()\n",
    "\n",
    "    def add_model_reply(self, reply: str, includes_history=True, return_reply=True):\n",
    "        reply_ = reply.replace(self.build_prompt(), \"\") if includes_history else reply\n",
    "        self.model_replies.append(reply_)\n",
    "        if len(self.user_messages) != len(self.model_replies):\n",
    "            raise ValueError(\n",
    "                \"Number of user messages does not equal number of system replies.\"\n",
    "            )\n",
    "        if return_reply:\n",
    "            return reply_\n",
    "\n",
    "    def get_user_messages(self, strip=True):\n",
    "        return [x.strip() for x in self.user_messages] if strip else self.user_messages\n",
    "\n",
    "    def get_model_replies(self, strip=True):\n",
    "        return [x.strip() for x in self.model_replies] if strip else self.model_replies\n",
    "\n",
    "    def clear_chat_history(self):\n",
    "        self.user_messages.clear()\n",
    "        self.model_replies.clear()\n",
    "\n",
    "    def build_prompt(self):\n",
    "        if self.user_messages == [] and self.model_replies == []:\n",
    "            return f\"<s>[INST] <<SYS>>\\n{self.system_prompt}\\n<</SYS>> [/INST]</s>\"\n",
    "        \n",
    "        elif len(self.user_messages) != len(self.model_replies) + 1:\n",
    "            raise ValueError(\n",
    "                \"Error: Expected len(user_messages) = len(model_replies) + 1. Add a new user message!\"\n",
    "            )\n",
    "\n",
    "        if self.system_prompt is not None:\n",
    "            SYS = f\"[INST] <<SYS>>\\n{self.system_prompt}\\n<</SYS>>\"\n",
    "        else:\n",
    "            SYS = \"\"\n",
    "\n",
    "        CONVO = \"\"\n",
    "        SYS = \"<s>\" + SYS\n",
    "        for i in range(len(self.user_messages) - 1):\n",
    "            user_message, model_reply = self.user_messages[i], self.model_replies[i]\n",
    "            conversation_ = f\"{user_message} [/INST] {model_reply} </s>\"\n",
    "            if i != 0:\n",
    "                conversation_ = \"[INST] \" + conversation_\n",
    "            CONVO += conversation_\n",
    "\n",
    "        CONVO += f\"[INST] {self.user_messages[-1]} [/INST]\"\n",
    "\n",
    "        return SYS + CONVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_prompt(llama_model:AutoModelForCausalLM, llama_tokenizer:AutoTokenizer, caption_list:list, context_prompt:str='', device:str='cuda'):\n",
    "    \"\"\"\n",
    "    Function to generate text-prompt pair with llama\n",
    "\n",
    "    Args:\n",
    "        llama_model (AutoModelForCausalLM): llama model\n",
    "        llama_tokenizer (AutoTokenizer): llama tokenizer\n",
    "        caption_list (list): list of captions from screenshots\n",
    "        context_prompt (str): llama context prompt, if '' the default prompt will be used. Defaults to ''\n",
    "    \"\"\"\n",
    "\n",
    "    if context_prompt == '':\n",
    "        context_prompt=f\"\"\"context={caption_list[0]},{caption_list[1]},{caption_list[2]},{caption_list[3]},{caption_list[4]}. \n",
    "        imagine you are writing a description of a video. You are capturing the emotions caused by the environment and atmosphere. You should write a 30 word paragraph that takes the 5 context and summarise all of them into that one paragraph. Talk about the environment, the vibes and the emotions. Immediately starts describing and do not mention the source. I will give you example prompts, follow their formatting but not the content. Give me just the paragraph and nothing else. \n",
    "        example prompts:\n",
    "        A small rural village. The atmosphere is peaceful, with citizens doing their daily tasks. However, there is an underlying tension in the air, like something is about to go down. The overall emotion of the video is one of suspense and intrigue.\"\"\"\n",
    "\n",
    "    # Initialize the prompt generator with the given context\n",
    "    prompt = PromptTemplate(context_prompt)\n",
    "    true_prompt = prompt.build_prompt()\n",
    "\n",
    "    config = GenerationConfig(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample= True,\n",
    "        top_k= 10,\n",
    "        num_return_sequences= 1,\n",
    "        return_full_text= False,\n",
    "        temperature= 0.1,\n",
    "    )\n",
    "\n",
    "    encoded_input = llama_tokenizer.encode(true_prompt, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    results = llama_model.generate(encoded_input, generation_config=config)\n",
    "    decoded_output = llama_tokenizer.decode(results[0], skip_special_tokens=True)\n",
    "    response = decoded_output.split(\"[/INST]\")[-1].strip()\n",
    "    #The response might not be consistent with the format, please explore and edit accordingly\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overarching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_textmusic_dataset(yt_api_key:str,\n",
    "                               kosmos_model:AutoModelForVision2Seq,\n",
    "                               kosmos_processor:AutoProcessor,\n",
    "                               llama_model:AutoModelForCausalLM,\n",
    "                               llama_tokenizer:AutoTokenizer,\n",
    "                               music_output_dir:str, \n",
    "                               dataset_csv_dir:str,\n",
    "                               music_csv_path:str='myseg.csv',\n",
    "                               search_term:str=\"no commentary walkthrough\", \n",
    "                               video_duration:list=[240, 3600], \n",
    "                               video_limit:int=10,\n",
    "                               clips_per_video:int=10, \n",
    "                               clips_length:int=30,\n",
    "                               music_length_threshold:int=25,\n",
    "                               screenshot_interval:list=[5,10,15,20,25],\n",
    "                               kosmos_text_input:str=\"detailed\", \n",
    "                               llama_context_prompt:str='',\n",
    "                               device:str='cuda'\n",
    "                               ):\n",
    "    \"\"\"\n",
    "    Function to generate dataset\n",
    "\n",
    "    Args:\n",
    "        yt_api_key (str): yt api key\n",
    "        kosmos_model (AutoModelForVision2Seq): kosmos model\n",
    "        kosmos_processor (AutoProcessor): kosmos tokenizer\n",
    "        llama_model (AutoModelForCausalLM): llama model\n",
    "        llama_tokenizer (AutoTokenizer): llama tokenizer\n",
    "        \n",
    "        music_output_dir (str): path to the dataset folder\n",
    "        dataset_csv_dir (str): path to the csv containing the filepath of video and the text prompt\n",
    "        music_csv_path (str, optional): music csv path for music split in each clip. Defaults to 'myseg.csv'.\n",
    "        \n",
    "        search_term (str, optional): youtube search time. Defaults to \"no commentary walkthrough\".\n",
    "        video_duration (list, optional): accepted videos will be within this duration. Defaults to [240, 3600].\n",
    "        video_limit (int, optional): maximum num of videos to be processed. Defaults to 10.\n",
    "        \n",
    "        clips_per_video (int, optional): number of clips to cut per video. Defaults to 10.\n",
    "        clips_length (int, optional): length of each clips in seconds. Defaults to 30.\n",
    "        \n",
    "        music_length_threshold (int, optional): threshold for how long music must be in seconds. Defaults to 25.\n",
    "        screenshot_interval (list, optional): List of times in seconds at which to capture the screenshots. Defaults to [5,10,15,20,25].\n",
    "        \n",
    "        kosmos_text_input (str, optional): grounding prompts. Using brief, or detailed will use pre-defined prompts. Defaults to detailed\n",
    "        llama_context_prompt (str, optional): llama context prompt, if '' the default prompt will be used. Defaults to ''. Defaults to ''.\n",
    "        device (str, optional): cuda or cpu. Defaults to cuda\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    base_dir = os.path.dirname(dataset_csv_dir)\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    with open(dataset_csv_dir, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Check if the file is empty to decide on writing headers\n",
    "        file.seek(0, os.SEEK_END)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(['Video Path', 'Caption'])\n",
    "\n",
    "        #extract youtube links\n",
    "        video_urls = fetch_videos(yt_api_key, search_term, video_duration, video_limit)\n",
    "        for url in video_urls:\n",
    "            #download and crop videos\n",
    "            clip_paths_list = download_extract_clips(url, music_output_dir, clips_per_video, clips_length)\n",
    "            for clip_path in clip_paths_list:\n",
    "                #extract videos and check music length\n",
    "                clip_path = check_music_length(clip_path, music_csv_path, music_length_threshold)\n",
    "                if clip_path is not None:\n",
    "                    #extract screenshots\n",
    "                    screenshot_paths = capture_screenshots(clip_path, screenshot_interval)\n",
    "                    caption_list = []\n",
    "                    for screenshots in screenshot_paths.values():\n",
    "                        #caption images\n",
    "                        caption_list.append(caption_image(kosmos_model, kosmos_processor, screenshots, kosmos_text_input, device))\n",
    "                        os.remove(screenshots)\n",
    "\n",
    "                    #text prompt\n",
    "                    text_prompt = generate_text_prompt(llama_model, llama_tokenizer, caption_list, llama_context_prompt, device)\n",
    "                    writer.writerow([clip_path, text_prompt])\n",
    "\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos = \"microsoft/kosmos-2-patch14-224\"\n",
    "kosmos_model = AutoModelForVision2Seq.from_pretrained(kosmos).to(\"cuda\")\n",
    "kosmos_processor = AutoProcessor.from_pretrained(kosmos)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" \n",
    "llama_model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-chat-hf', token=hg_key, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-chat-hf', token=hg_key)\n",
    "print(f\"Model running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_textmusic_dataset(yt_API, \n",
    "                           kosmos_model, \n",
    "                           kosmos_processor,\n",
    "                           llama_model,\n",
    "                           llama_tokenizer,\n",
    "                           '../../input/text-music-dataset/',\n",
    "                           '../../input/text-music-dataset/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
