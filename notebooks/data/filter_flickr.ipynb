{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Flickr30k Dataset\n",
    "- Perform zero-shot classification with bart-large-mnli model\n",
    "- Define labels on both landscape and non-landscape categories\n",
    "- Set threshold for each label under landscape category\n",
    "- Classify the filtered dataset into the primary five classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(input_csv, output_csv, labels):\n",
    "    \"\"\"\n",
    "    Performs zero-shot classification on captions from an input CSV and saves the results to an output CSV.\n",
    "\n",
    "    Args:\n",
    "        input_csv: Path to the input CSV file.\n",
    "        output_csv: Path where the output CSV file will be saved.\n",
    "        labels: A list of labels for classification.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "    results = []\n",
    "    for caption in df['caption']:\n",
    "        result = classifier(caption, labels, multi_label=False)\n",
    "        results.append((result['labels'][0], result['scores'][0]))\n",
    "\n",
    "    df['label'], df['score'] = zip(*results)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Classification completed and saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"beach\", \"lake\", \"glacier\", \"mountains\", \"snow\", \"desert\", \"sand\", \"forest\", \"sea\", \"park\", \"ice\", \"city\", \"indoor\", \"stadium\", \"urban\", \"grass\", \"pool\", \"garden\"]\n",
    "zero_shot_classification('../../input/Flickr30k/captions.csv', '../../input/Flickr30k/flick30k_all_result.csv', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_flickr(input_csv, output_csv, thresholds):\n",
    "    \"\"\"\n",
    "    Filters captions based on predefined thresholds for each label and saves the filtered results to a CSV.\n",
    "\n",
    "    Args:\n",
    "        input_csv: Path to the CSV file containing captions and their classification scores.\n",
    "        output_csv: Path where the filtered results will be saved.\n",
    "        thresholds: Dictionary where keys are labels and values are the minimum score thresholds for those labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    def filter_row(row):\n",
    "        return row['label'] in thresholds and row['score'] >= thresholds[row['label']]\n",
    "\n",
    "    filtered_result_df = df[df.apply(filter_row, axis=1)]\n",
    "\n",
    "    filtered_result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Total number of qualifying captions: {len(filtered_result_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'sea': 0.7,\n",
    "    'beach': 0.5,\n",
    "    'desert': 0.8,\n",
    "    'forest': 0.7,\n",
    "    'glacier': 0.2,\n",
    "    'mountains': 0.3,  \n",
    "    'snow': 0.5,\n",
    "    'sand': 0.4,\n",
    "    'lake': 0.4\n",
    "}\n",
    "\n",
    "filter_flickr('../../input/Flickr30k/flick30k_all_result.csv', '../../input/Flickr30k/flick30k_filtered_result.csv', thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(csv_file, directories, output_folder):\n",
    "    \"\"\"\n",
    "    Extract images listed in a CSV file from multiple directories and save them to an output folder.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file containing image filenames.\n",
    "        directories (list): List of directories to search for the images.\n",
    "        output_folder (str): Path to the output folder where the images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of filenames of images that were not found in any of the provided directories.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_filenames = df['image_filename'].unique()\n",
    "\n",
    "    not_found_images = [] \n",
    "\n",
    "    for filename in image_filenames:\n",
    "        found = False  \n",
    "        for dir in directories:\n",
    "            source_path = os.path.join(dir, filename)\n",
    "            if os.path.exists(source_path):\n",
    "                shutil.copy2(source_path, os.path.join(output_folder, filename))\n",
    "                print(f\"Copied {filename} to {output_folder}\")\n",
    "                found = True\n",
    "                break \n",
    "        if not found:\n",
    "            not_found_images.append(filename)\n",
    "\n",
    "    if not_found_images:\n",
    "        print(\"Images not found in any of the provided directories:\")\n",
    "        for img in not_found_images:\n",
    "            print(img)\n",
    "\n",
    "    return not_found_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '../../input/Flicker30k/flick30k_filtered_result.csv'\n",
    "flicker_image_files = ['../../input/Flickr30k/flickr30k_images/']\n",
    "\n",
    "flicker_filtered_image = '../../input/Flickr30k/flicker30k_output_images/'\n",
    "extract_images(csv_file, flicker_image_files, flicker_filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_flickr(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Loads a CSV, maps labels to new categories, determines the most representative label for each image, and saves the results.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path: Path to the input CSV file containing labeled data.\n",
    "        output_csv_path: Path where the categorized and classified results will be saved. \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    label_map = {\n",
    "        'beach': 'coast',\n",
    "        'lake': 'coast',\n",
    "        'glacier': 'glacier',\n",
    "        'mountain': 'mountain',\n",
    "        'snow': 'glacier',\n",
    "        'desert': 'desert',\n",
    "        'sand': 'desert',\n",
    "        'forest': 'forest',\n",
    "        'sea': 'coast'\n",
    "    }\n",
    "\n",
    "    df['new_label'] = df['label'].map(label_map)\n",
    "\n",
    "    def determine_label(group):\n",
    "        label_counts = group['new_label'].value_counts()\n",
    "        if len(label_counts) == 1 or label_counts.iloc[0] > label_counts.iloc[1]:\n",
    "            return label_counts.idxmax()\n",
    "        else:\n",
    "            return group.sort_values('score', ascending=False)['new_label'].iloc[0]\n",
    "\n",
    "    grouped = df.groupby('image_filename')\n",
    "    df['classified_label'] = grouped.apply(lambda x: determine_label(x))\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"File saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_flickr('../../input/Flicker30k/flick30k_filtered_result.csv', 'classified_images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other Method Conducted on Filtering and Classifying the dataset \n",
    "Experimented filtering by using Cosine Similarity Check with landscape data, Zero-shot classifaction with OpenAI CLIP Model, different way of filtered the zero-shot result generated by bart-large-mnli model. Also, tried using OpanAI Clip Model to classify the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Another way of filter flickr dataset\n",
    "# Looking through all captions of each image, choose those image with at least 3 captions that meets the threshold of the label\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_flickr(input_csv, output_csv, thresholds, min_label_count=3):\n",
    "    \"\"\"\n",
    "    Filters images based on the specified thresholds for each label, requiring at least a certain number of labels \n",
    "    to exceed their threshold to qualify an image.\n",
    "\n",
    "    Args:\n",
    "        input_csv: Path to the input CSV file containing labeled data.\n",
    "        output_csv: Path where the filtered results will be saved.\n",
    "        thresholds: Dictionary where keys are labels and values are the minimum confidence thresholds for those labels.\n",
    "        min_label_count: Minimum number of times a label must exceed its threshold to qualify an image.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    grouped = df.groupby('image_filename')\n",
    "    qualify_images = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        label_counts = {label: 0 for label in thresholds.keys()}\n",
    "        for _, row in group.iterrows():\n",
    "            if row['label'] in thresholds and row['confidence'] >= thresholds[row['label']]:\n",
    "                label_counts[row['label']] += 1\n",
    "\n",
    "        if sum(count >= min_label_count for count in label_counts.values()) >= 1:\n",
    "            qualify_images.append(name)\n",
    "\n",
    "    filtered_result_df = df[df['image_filename'].isin(qualify_images)]\n",
    "    filtered_result_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Total number of qualifying images: {len(qualify_images)}\")\n",
    "\n",
    "thresholds = {\n",
    "    'sea': 0.7,\n",
    "    'beach': 0.5,\n",
    "    'desert': 0.8,\n",
    "    'forest': 0.7,\n",
    "    'glacier': 0.2,\n",
    "    'mountain': 0.5,\n",
    "    'snow': 0.5,\n",
    "    'sand': 0.5,\n",
    "    'lake': 0.5\n",
    "}\n",
    "\n",
    "filter_flickr('flick30k_all_result.csv', 'flick30k_filtered_result.csv', thresholds)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Caption Similarity Check with Kosomos and Blip Caption\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_tfidf(ref_file1, ref_file2, new_file):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF vectors for reference captions and new captions.\n",
    "\n",
    "    Args:\n",
    "        ref_file1 (str): Path to the first reference CSV file containing image captions.\n",
    "        ref_file2 (str): Path to the second reference CSV file containing image captions.\n",
    "        new_file (str): Path to the new CSV file containing image captions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing TF-IDF vectors for reference captions (ref_vectors),\n",
    "               TF-IDF vectors for new captions (new_vectors), and a DataFrame of new captions (new_captions_df).\n",
    "    \"\"\"\n",
    "    ref_captions1 = pd.read_csv(ref_file1)['image_caption'].tolist()\n",
    "    ref_captions2 = pd.read_csv(ref_file2)['image_caption'].tolist()\n",
    "    ref_captions = ref_captions1 + ref_captions2\n",
    "    \n",
    "    new_captions_df = pd.read_csv(new_file)\n",
    "    new_captions = new_captions_df['caption'].tolist()\n",
    "\n",
    "    all_captions = ref_captions + new_captions\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_captions_vectors = vectorizer.fit_transform(all_captions)\n",
    "\n",
    "    ref_vectors = all_captions_vectors[:len(ref_captions)]\n",
    "    new_vectors = all_captions_vectors[len(ref_captions):]\n",
    "\n",
    "    return ref_vectors, new_vectors, new_captions_df\n",
    "\n",
    "def filter_flicker(ref_vectors, new_vectors, new_captions_df, threshold, output_file):\n",
    "    \"\"\"\n",
    "    Filter new captions based on similarity to reference captions using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        ref_vectors (array-like): TF-IDF vectors of reference captions.\n",
    "        new_vectors (array-like): TF-IDF vectors of new captions.\n",
    "        new_captions_df (DataFrame): DataFrame containing new captions.\n",
    "        threshold (float): Similarity threshold for filtering.\n",
    "        output_file (str): Path to save the filtered captions.\n",
    "    \"\"\"\n",
    "    similarities = cosine_similarity(new_vectors, ref_vectors)\n",
    "    max_similarities = np.max(similarities, axis=1)\n",
    "    new_captions_df['similarity_score'] = max_similarities\n",
    "\n",
    "    qualifying_images = set()\n",
    "\n",
    "    for filename in new_captions_df['image_filename'].unique():\n",
    "        image_data = new_captions_df[new_captions_df['image_filename'] == filename]\n",
    "        qualifying_captions = image_data[image_data['similarity_score'] >= threshold]\n",
    "\n",
    "        if len(qualifying_captions) >= 2:\n",
    "            qualifying_images.add(filename)\n",
    "\n",
    "    filtered_df = new_captions_df[new_captions_df['image_filename'].isin(qualifying_images)]\n",
    "\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered captions saved to {output_file}. Total qualifying images: {len(qualifying_images)}\")\n",
    "\n",
    "blip_label = '../../input/Landscape/Label/Blip_Label.csv'\n",
    "kosomos_label = '../../input/Landscape/Label/Kosmos_Label.csv'\n",
    "filtered_flicker30k = 'flick30k_filtered_result.csv'\n",
    "\n",
    "ref_vectors, new_vectors, new_captions_df = compute_tfidf(blip_label, kosomos_label, filtered_flicker30k)\n",
    "\n",
    "filter_flicker(ref_vectors, new_vectors, new_captions_df, 0.4, 'flicker30k_output_file.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Using CLIP Model to filter the landscape image\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "def is_landscape(image_path, positive_categories, negative_categories, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Determine if an image depicts a landscape based on given positive and negative categories.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        positive_categories (list): List of positive categories related to landscapes.\n",
    "        negative_categories (list): List of negative categories not related to landscapes.\n",
    "        threshold (float): Threshold for classification probability, defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the maximum positive probability and maximum negative probability.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"File is not an image or cannot be opened: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    inputs = processor(text=positive_categories + negative_categories, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "    positive_probs = probs[0][:len(positive_categories)]\n",
    "    negative_probs = probs[0][len(positive_categories):]\n",
    "\n",
    "    max_positive_prob = max(positive_probs).item()\n",
    "    max_negative_prob = max(negative_probs).item()\n",
    "\n",
    "    print(f\"Image: {image_path}, Positive Probability: {max_positive_prob}, Negative Probability: {max_negative_prob}\")\n",
    "\n",
    "    return max_positive_prob, max_negative_prob\n",
    "\n",
    "def classify_images(folder_path, output_folder, positive_categories, negative_categories, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classify images in a folder into 'similar' or 'landscape' categories based on positive and negative categories.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        output_folder (str): Path to the output folder.\n",
    "        positive_categories (list): List of positive categories related to landscapes.\n",
    "        negative_categories (list): List of negative categories not related to landscapes.\n",
    "        threshold (float): Threshold for classification probability, defaults to 0.5.\n",
    "    \"\"\"\n",
    "    similar_folder = os.path.join(output_folder, 'similar')\n",
    "    landscape_folder = os.path.join(output_folder, 'landscape')\n",
    "    \n",
    "    if not os.path.exists(similar_folder):\n",
    "        os.makedirs(similar_folder)\n",
    "    if not os.path.exists(landscape_folder):\n",
    "        os.makedirs(landscape_folder)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    total_images = len(image_files)\n",
    "    similar_count, landscape_count = 0, 0\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        positive_prob, negative_prob = is_landscape(image_path, positive_categories, negative_categories, threshold)\n",
    "        \n",
    "        if positive_prob is None or negative_prob is None:\n",
    "            continue\n",
    "        \n",
    "        if negative_prob > positive_prob:\n",
    "            continue\n",
    "\n",
    "        destination_folder = None\n",
    "        if abs(positive_prob - negative_prob) <= 0.1:\n",
    "            destination_folder = similar_folder\n",
    "            similar_count += 1\n",
    "        elif positive_prob > threshold:\n",
    "            destination_folder = landscape_folder\n",
    "            landscape_count += 1\n",
    "        \n",
    "        if destination_folder:\n",
    "            shutil.copy2(image_path, os.path.join(destination_folder, image_file))\n",
    "\n",
    "    print(f\"Total number of images: {total_images}\")\n",
    "    print(f\"Number of images in 'similar' folder: {similar_count}\")\n",
    "    print(f\"Number of images in 'landscape' folder: {landscape_count}\")\n",
    "\n",
    "positive_categories = [\"mountain\", \"desert\", \"snow\", \"sea\", \"glacier\", \"beach\"]\n",
    "negative_categories = [\"water\", \"city\", \"indoor\", \"parks\", \"grass\", \"urban\", \"pool\", \"stadium\", \"lake\", \"building\", \"street\", \"transport\", \"house\", \"shop\", \"garden\", \"traffic\"]\n",
    "folder_path = flicker_filtered_image\n",
    "output_folder = '../../input/Flicker8k/Output/Zero_Shot'\n",
    "classify_images(folder_path, output_folder, positive_categories, negative_categories)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Classify each image into the 5 Landscape class\n",
    "image_directory = '../../input/flicker30k/flicker30k_output_images'\n",
    "df = pd.read_csv('../../input/Flicker30k/flick30k_filtered_result.csv')\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "\n",
    "target_classes = ['glacier', 'coast', 'forest', 'mountains', 'desert']\n",
    "\n",
    "descriptive_texts = {\n",
    "    'glacier': 'A vast body of ice',\n",
    "    'coast': 'Where the land meets the sea',\n",
    "    'forest': 'A dense collection of trees and plants',\n",
    "    'mountains': 'Tall and rocky natural elevations',\n",
    "    'desert': 'A hot, sandy, and arid region'\n",
    "}\n",
    "\n",
    "def classify_with_clip(image_filename):\n",
    "    \"\"\"\n",
    "    Classify an image using CLIP model.\n",
    "\n",
    "    Args:\n",
    "        image_filename (str): Filename of the image.\n",
    "\n",
    "    Returns:\n",
    "        str: The determined image class.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(image_directory, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"No such file: {image_path}\")\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    texts = list(descriptive_texts.values())\n",
    "    inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "    max_index = probs.argmax().item()\n",
    "    chosen_class = list(descriptive_texts.keys())[max_index]\n",
    "    return chosen_class\n",
    "\n",
    "def determine_image_class(group):\n",
    "    \"\"\"\n",
    "    Determine the class of an image group.\n",
    "\n",
    "    Args:\n",
    "        group (DataFrame): Group of images.\n",
    "\n",
    "    Returns:\n",
    "        str: The determined image class.\n",
    "    \"\"\"\n",
    "    labels = group['label'].tolist()\n",
    "    if len(set(labels)) == 1 and labels[0] in target_classes:\n",
    "        return labels[0]\n",
    "    else:\n",
    "        return classify_with_clip(group.name)\n",
    "\n",
    "image_classes = df.groupby('image_filename').apply(determine_image_class)\n",
    "\n",
    "df['image_class'] = df['image_filename'].map(image_classes)\n",
    "df.to_csv('../../input/Flicker30k/flick30k_filtered_result_updated.csv', index=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
