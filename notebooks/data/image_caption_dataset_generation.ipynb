{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kosmos-2 Image Caption Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq #If we using kosmos-2\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kosmos2_image_text_pair(model:AutoModelForVision2Seq, processor:AutoProcessor, source_folder_path=str, dest_folder_path=str):\n",
    "    \"\"\"\n",
    "    Function to generate image caption pair using kosmos_2 model. \n",
    "    \n",
    "    Args:\n",
    "        model (AutoModelForVision2Seq): Kosmos-2 model,\n",
    "        processor (AutoProcessor): Kosmos-2 model tokenizer\n",
    "        source_folder_path (str): Path to image folder containing all images\n",
    "        dest_folder_path (str): Path to labels folder where the csv will be stored as label.csv\n",
    "    \n",
    "    Output:\n",
    "        CSV file that container the image name and the respective image caption generated\n",
    "        CSV file will auto save every 100 images as a checkpoint    \n",
    "    \"\"\"\n",
    "    all_images_names = os.listdir(source_folder_path)\n",
    "    text_input = \"<grounding>An image of\"\n",
    "\n",
    "    image_dataframe = pd.DataFrame(columns=['image_filename', 'image_caption'])\n",
    "\n",
    "    with tqdm(total=len(all_images_names)) as pbar:\n",
    "        for index, image_name in enumerate(all_images_names):\n",
    "            #read image\n",
    "            image_path = f\"{source_folder_path}/{image_name}\"\n",
    "            image_input = Image.open(image_path)\n",
    "\n",
    "            #process image and text input into tensors\n",
    "            inputs = processor(text=text_input, images=image_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "            #run data through the model\n",
    "            generated_ids = model.generate(\n",
    "                pixel_values=inputs[\"pixel_values\"],\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                image_embeds=None,\n",
    "                image_embeds_position_mask=inputs[\"image_embeds_position_mask\"],\n",
    "                use_cache=True,\n",
    "                max_new_tokens=128,\n",
    "            )\n",
    "\n",
    "            #decode output into readable text\n",
    "            generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            processed_text, entities = processor.post_process_generation(generated_text)\n",
    "            image_caption = processed_text.replace(\"An image of \", \"\")\n",
    "            image_dataframe.loc[len(image_dataframe)] = [image_name, image_caption.strip()]\n",
    "\n",
    "            #Auto checkpoint saving at every 100\n",
    "            if index % 100 == 0:\n",
    "                image_dataframe.to_csv(f\"{dest_folder_path}/Kosmos_Label.csv\")\n",
    "\n",
    "            pbar.update(1)\n",
    "        #Save final data\n",
    "        image_dataframe.to_csv(f\"{dest_folder_path}/Kosmos_Label.csv\")\n",
    "\n",
    "        pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../input/Image Captions/Train/Images\"\n",
    "train_dest_path = \"../input/Image Captions/Train/Labels\"\n",
    "\n",
    "test_file_path = \"../input/Image Captions/Test/Images\"\n",
    "test_dest_path = \"../input/Image Captions/Test/Labels\"\n",
    "\n",
    "val_file_path = \"../input/Image Captions/Validation/Images\"\n",
    "val_dest_path = \"../input/Image Captions/Validation/Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForVision2Seq.from_pretrained(\"microsoft/kosmos-2-patch14-224\").to(\"cuda\")\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/kosmos-2-patch14-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:11<00:00,  3.72s/it]\n",
      "100%|██████████| 100/100 [05:57<00:00,  3.58s/it]\n",
      "100%|██████████| 100/100 [06:36<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "source_paths = [test_file_path, train_file_path, val_file_path]\n",
    "dest_paths = [test_dest_path, train_dest_path, val_dest_path]\n",
    "\n",
    "for index, source_path in enumerate(source_paths):\n",
    "    kosmos2_image_text_pair(model, processor, source_path, dest_paths[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLIP2 Image Caption Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration #If we using BLIP (JIC we want more data)\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLIP2_image_text_pair(model:Blip2ForConditionalGeneration, processor:Blip2Processor, source_folder_path=str, dest_folder_path=str):\n",
    "    \"\"\"\n",
    "    Function to generate image caption pair using BLIP2 model. \n",
    "    \n",
    "    Args:\n",
    "        model (Blip2ForConditionalGeneration): Kosmos-2 model,\n",
    "        processor (Blip2Processor): Kosmos-2 model tokenizer\n",
    "        source_folder_path (str): Path to image folder containing all images\n",
    "        dest_folder_path (str): Path to labels folder where the csv will be stored as label.csv\n",
    "    \n",
    "    Output:\n",
    "        CSV file that container the image name and the respective image caption generated\n",
    "        CSV file will auto save every 100 images as a checkpoint    \n",
    "    \"\"\"\n",
    "    all_images_names = os.listdir(source_folder_path)\n",
    "\n",
    "    image_dataframe = pd.DataFrame(columns=['image_filename', 'image_caption'])\n",
    "\n",
    "    with tqdm(total=len(all_images_names)) as pbar:\n",
    "        for index, image_name in enumerate(all_images_names):\n",
    "            #read image\n",
    "            image_path = f\"{source_folder_path}/{image_name}\"\n",
    "            image_input = Image.open(image_path)\n",
    "\n",
    "            #process image and text input into tensors\n",
    "            inputs = processor(image_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "            #run data through the model\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=20,\n",
    "            )\n",
    "\n",
    "            #decode output into readable text\n",
    "            generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            image_dataframe.loc[len(image_dataframe)] = [image_name, generated_text.strip()]\n",
    "\n",
    "            #Auto checkpoint saving at every 100\n",
    "            if index % 100 == 0:\n",
    "                image_dataframe.to_csv(f\"{dest_folder_path}/Blip_Label.csv\")\n",
    "\n",
    "            pbar.update(1)\n",
    "        #Save entire dataset\n",
    "        image_dataframe.to_csv(f\"{dest_folder_path}/Blip_Label.csv\")\n",
    "        pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"../input/Image Captions/Train/Images\"\n",
    "train_dest_path = \"../input/Image Captions/Train/Labels\"\n",
    "\n",
    "test_file_path = \"../input/Image Captions/Test/Images\"\n",
    "test_dest_path = \"../input/Image Captions/Test/Labels\"\n",
    "\n",
    "val_file_path = \"../input/Image Captions/Validation/Images\"\n",
    "val_dest_path = \"../input/Image Captions/Validation/Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", device_map=\"auto\")\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:44<00:00,  1.06s/it]\n",
      "100%|██████████| 99/99 [01:35<00:00,  1.04it/s]\n",
      "100%|██████████| 99/99 [01:40<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "source_paths = [test_file_path, train_file_path, val_file_path]\n",
    "dest_paths = [test_dest_path, train_dest_path, val_dest_path]\n",
    "\n",
    "for index, source_path in enumerate(source_paths):\n",
    "    BLIP2_image_text_pair(model, processor, source_path, dest_paths[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
