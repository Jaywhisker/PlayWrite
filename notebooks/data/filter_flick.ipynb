{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../input/Flicker30k/captions.csv') \n",
    "\n",
    "classifier = pipeline('text-classification', model='bert-base-uncased')\n",
    "\n",
    "def classify_caption(caption):\n",
    "    try:\n",
    "        results = classifier(caption, truncation=True)[0] \n",
    "        return pd.Series([results['label'], results['score']])\n",
    "    except Exception as e:\n",
    "        return pd.Series(['error', 0])\n",
    "\n",
    "df[['label', 'score']] = df['caption'].apply(classify_caption)\n",
    "\n",
    "df.to_csv('../../input/Flicker30k/flick30k_all_result.csv', index=False)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Caption: {row['caption']}, Category: {row['label']}, Score: {row['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../input/Flicker30k/flick30k_all_result.csv')\n",
    "\n",
    "thresholds = {\n",
    "    'sea': 0.7,\n",
    "    'beach': 0.5,\n",
    "    'desert': 0.8,\n",
    "    'forest': 0.7,\n",
    "    'glacier': 0.2,\n",
    "    'mountain': 0.3,\n",
    "    'snow': 0.5,\n",
    "    'sand': 0.4,\n",
    "    'lake': 0.4\n",
    "}\n",
    "\n",
    "def filter_row(row):\n",
    "    return row['label'] in thresholds and row['confidence'] >= thresholds[row['label']]\n",
    "\n",
    "filtered_result_df = df[df.apply(filter_row, axis=1)]\n",
    "\n",
    "filtered_result_df.to_csv('../../input/Flicker30k/flick30k_filtered_result.csv', index=False)\n",
    "\n",
    "print(f\"Total number of qualifying captions: {len(filtered_result_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking total number of filtered images\n",
    "df = pd.read_csv('../../input/Flicker30k/flick30k_filtered_result.csv')\n",
    "\n",
    "unique_image_filenames_count = df['image_filename'].nunique()\n",
    "\n",
    "print(f\"Number of unique image filenames: {unique_image_filenames_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(csv_file, directories, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_filenames = df['image_filename'].unique()\n",
    "\n",
    "    not_found_images = [] \n",
    "\n",
    "    for filename in image_filenames:\n",
    "        found = False  \n",
    "        for dir in directories:\n",
    "            source_path = os.path.join(dir, filename)\n",
    "            if os.path.exists(source_path):\n",
    "                shutil.copy2(source_path, os.path.join(output_folder, filename))\n",
    "                print(f\"Copied {filename} to {output_folder}\")\n",
    "                found = True\n",
    "                break \n",
    "        if not found:\n",
    "            not_found_images.append(filename)\n",
    "\n",
    "    if not_found_images:\n",
    "        print(\"Images not found in any of the provided directories:\")\n",
    "        for img in not_found_images:\n",
    "            print(img)\n",
    "\n",
    "    return not_found_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '../../input/Flicker30k/flick30k_filtered_result.csv'\n",
    "flicker_image_files = ['../../input/Flicker30k/flickr30k_images/']\n",
    "\n",
    "flicker_filtered_image = '../../input/flicker30k/flicker30k_output_images/'\n",
    "extract_images(csv_file, flicker_image_files, flicker_filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Looking through all captions of each image, choose those image with at least 3 captions that meets the threshold of the label\n",
    "\n",
    "df = pd.read_csv('flick30k_all_result.csv')\n",
    "\n",
    "thresholds = {\n",
    "    'sea': 0.7,\n",
    "    'beach': 0.5,\n",
    "    'desert': 0.8,\n",
    "    'forest': 0.7,\n",
    "    'glacier': 0.2,\n",
    "    'mountain': 0.5,\n",
    "    'snow': 0.5,\n",
    "    'sand': 0.5,\n",
    "    'lake': 0.5\n",
    "}\n",
    "\n",
    "qualify_images = []\n",
    "\n",
    "grouped = df.groupby('image_filename')\n",
    "for name, group in grouped:\n",
    "    label_counts = {label: 0 for label in thresholds.keys()} \n",
    "    for _, row in group.iterrows():\n",
    "        if row['label'] in thresholds and row['confidence'] >= thresholds[row['label']]:\n",
    "            label_counts[row['label']] += 1\n",
    "    \n",
    "    if sum(count >= 3 for count in label_counts.values()) >= 1:\n",
    "        qualify_images.append(name)\n",
    "\n",
    "filtered_result_df = df[df['image_filename'].isin(qualify_images)]\n",
    "\n",
    "filtered_result_df.to_csv('flick30k_filtered_result.csv', index=False)\n",
    "\n",
    "print(f\"Total number of qualifying images: {len(qualify_images)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Caption Similarity Check with Kosomos and Blip Caption\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_tfidf(ref_file1, ref_file2, new_file):\n",
    "    ref_captions1 = pd.read_csv(ref_file1)['image_caption'].tolist()\n",
    "    ref_captions2 = pd.read_csv(ref_file2)['image_caption'].tolist()\n",
    "    ref_captions = ref_captions1 + ref_captions2\n",
    "    \n",
    "    new_captions_df = pd.read_csv(new_file)\n",
    "    new_captions = new_captions_df['caption'].tolist()\n",
    "\n",
    "    all_captions = ref_captions + new_captions\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_captions_vectors = vectorizer.fit_transform(all_captions)\n",
    "\n",
    "    ref_vectors = all_captions_vectors[:len(ref_captions)]\n",
    "    new_vectors = all_captions_vectors[len(ref_captions):]\n",
    "\n",
    "    return ref_vectors, new_vectors, new_captions_df\n",
    "\n",
    "def filter_flicker(ref_vectors, new_vectors, new_captions_df, threshold, output_file):\n",
    "    similarities = cosine_similarity(new_vectors, ref_vectors)\n",
    "    max_similarities = np.max(similarities, axis=1)\n",
    "    new_captions_df['similarity_score'] = max_similarities\n",
    "\n",
    "    qualifying_images = set()\n",
    "\n",
    "    for filename in new_captions_df['image_filename'].unique():\n",
    "        image_data = new_captions_df[new_captions_df['image_filename'] == filename]\n",
    "        qualifying_captions = image_data[image_data['similarity_score'] >= threshold]\n",
    "\n",
    "        if len(qualifying_captions) >= 2:\n",
    "            qualifying_images.add(filename)\n",
    "\n",
    "    filtered_df = new_captions_df[new_captions_df['image_filename'].isin(qualifying_images)]\n",
    "\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered captions saved to {output_file}. Total qualifying images: {len(qualifying_images)}\")\n",
    "\n",
    "blip_label = '../../input/Landscape/Label/Blip_Label.csv'\n",
    "kosomos_label = '../../input/Landscape/Label/Kosmos_Label.csv'\n",
    "filtered_flicker30k = 'flick30k_filtered_result.csv'\n",
    "\n",
    "ref_vectors, new_vectors, new_captions_df = compute_tfidf(blip_label, kosomos_label, filtered_flicker30k)\n",
    "\n",
    "filter_flicker(ref_vectors, new_vectors, new_captions_df, 0.4, 'flicker30k_output_file.csv')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Using CLIP Model to filter the landscape image\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "def is_landscape(image_path, positive_categories, negative_categories, threshold=0.5):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"File is not an image or cannot be opened: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    inputs = processor(text=positive_categories + negative_categories, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "    positive_probs = probs[0][:len(positive_categories)]\n",
    "    negative_probs = probs[0][len(positive_categories):]\n",
    "\n",
    "    max_positive_prob = max(positive_probs).item()\n",
    "    max_negative_prob = max(negative_probs).item()\n",
    "\n",
    "    print(f\"Image: {image_path}, Positive Probability: {max_positive_prob}, Negative Probability: {max_negative_prob}\")\n",
    "\n",
    "    return max_positive_prob, max_negative_prob\n",
    "\n",
    "def classify_images(folder_path, output_folder, positive_categories, negative_categories, threshold=0.5):\n",
    "    similar_folder = os.path.join(output_folder, 'similar')\n",
    "    landscape_folder = os.path.join(output_folder, 'landscape')\n",
    "    \n",
    "    if not os.path.exists(similar_folder):\n",
    "        os.makedirs(similar_folder)\n",
    "    if not os.path.exists(landscape_folder):\n",
    "        os.makedirs(landscape_folder)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    total_images = len(image_files)\n",
    "    similar_count, landscape_count = 0, 0\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        positive_prob, negative_prob = is_landscape(image_path, positive_categories, negative_categories, threshold)\n",
    "        \n",
    "        if positive_prob is None or negative_prob is None:\n",
    "            continue\n",
    "        \n",
    "        if negative_prob > positive_prob:\n",
    "            continue\n",
    "\n",
    "        destination_folder = None\n",
    "        if abs(positive_prob - negative_prob) <= 0.1:\n",
    "            destination_folder = similar_folder\n",
    "            similar_count += 1\n",
    "        elif positive_prob > threshold:\n",
    "            destination_folder = landscape_folder\n",
    "            landscape_count += 1\n",
    "        \n",
    "        if destination_folder:\n",
    "            shutil.copy2(image_path, os.path.join(destination_folder, image_file))\n",
    "\n",
    "    print(f\"Total number of images: {total_images}\")\n",
    "    print(f\"Number of images in 'similar' folder: {similar_count}\")\n",
    "    print(f\"Number of images in 'landscape' folder: {landscape_count}\")\n",
    "\n",
    "positive_categories = [\"mountain\", \"desert\", \"snow\", \"sea\", \"glacier\", \"beach\"]\n",
    "negative_categories = [\"water\", \"city\", \"indoor\", \"parks\", \"grass\", \"urban\", \"pool\", \"stadium\", \"lake\", \"building\", \"street\", \"transport\", \"house\", \"shop\", \"garden\", \"traffic\"]\n",
    "folder_path = flicker_filtered_image\n",
    "output_folder = '../../input/Flicker8k/Output/Zero_Shot'\n",
    "classify_images(folder_path, output_folder, positive_categories, negative_categories)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
