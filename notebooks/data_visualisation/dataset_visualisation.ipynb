{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "- To undergo K-means clustering, we must first convert the captions to word embeddings\n",
    "- UMAP is used to reduce dimensionality to the data to allow for better clustering\n",
    "- Clustering with a fixed cluster size can be achieved with scikit k-means\n",
    "- Clustering with a non fixed cluster size can be achieved with HDBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "blip_train = pd.read_csv(\"../inputs/Image_Captions/Train/Labels/Blip_Label.csv\", index_col=0)\n",
    "blip_test = pd.read_csv(\"../inputs/Image_Captions/Test/Labels/Blip_Label.csv\", index_col=0)\n",
    "blip_val = pd.read_csv(\"../inputs/Image_Captions/Validation/Labels/Blip_Label.csv\", index_col=0)\n",
    "\n",
    "kosmos_train = pd.read_csv(\"../inputs/Image_Captions/Train/Labels/Kosmos_Label.csv\", index_col=0)\n",
    "kosmos_test = pd.read_csv(\"../inputs/Image_Captions/Test/Labels/Kosmos_Label.csv\", index_col=0)\n",
    "kosmos_val = pd.read_csv(\"../inputs/Image_Captions/Validation/Labels/Kosmos_Label.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe of all the captions\n",
    "blip = pd.concat([blip_train, blip_test, blip_val])\n",
    "kosmos = pd.concat([kosmos_train, kosmos_test, kosmos_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing sentences & Dimensionality Reduction\n",
    "By default, use `all-mpnet-base-v2` model to embed all our captions into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_captions(all_captions:list, device:str='cuda', embedding_model=None):  \n",
    "    \"\"\"\n",
    "    Tokenise list of captions based on the embedding model of choice\n",
    "\n",
    "    Args:\n",
    "        all_captions (list): List of captions\n",
    "        device (str, optional): cpu or cuda, defaults to cuda\n",
    "        embedding_model (optional): embedding model of choice, defaults to None.\n",
    "                                    if embedding_model is None, default of all-mpnet-base-v2 will be used\n",
    "\n",
    "    Returns:\n",
    "        embeddings: tokenized captions\n",
    "    \"\"\"\n",
    "    if embedding_model == None:\n",
    "        embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "    #tokenizing captions\n",
    "    embeddings = embedding_model.encode(all_captions, device=device)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def umap_reduction(sentence_embeddings, n_neighbours:int=100, n_components:int=3, metrics:str='cosine'):\n",
    "    \"\"\"\n",
    "    Reduce dimensionality of sentence embeddings with UMAP\n",
    "    Please refer to UMAP documents for more details: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "\n",
    "    Args:\n",
    "        sentence_embeddings: sentence embeddings\n",
    "        n_neighbours (int, optional): Balances local vs global structure, the larger the value, the more global the mapping. Defaults to 100.\n",
    "        n_components (int, optional): Dimension the data will be reduced to. Defaults to 3.\n",
    "        metrics (str, optional): Distance metrics  used for clustering. Defaults to 'cosine'.\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "        umap_embeddings: reduced sentence embeddings\n",
    "    \"\"\"\n",
    "    umap_embeddings = (umap.UMAP(n_neighbors= n_neighbours,\n",
    "                              n_components= n_components,\n",
    "                              metric= metrics)\n",
    "                              .fit_transform(sentence_embeddings))\n",
    "    \n",
    "    return umap_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_umap_embeddings = umap_reduction(embed_captions(blip['image_caption'].to_list()))\n",
    "kosmos_umap_embeddings = umap_reduction(embed_captions(kosmos['image_caption'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(embeddings, num_clusters:int, cluster_labels:list):\n",
    "    try:\n",
    "        #creating colours\n",
    "        colors = plt.cm.get_cmap('gist_rainbow', num_clusters)\n",
    "        cmap = ListedColormap(colors(np.linspace(0, 1, num_clusters)))\n",
    "        \n",
    "        #plot graph\n",
    "        plt.figure(figsize=(8, 8))  \n",
    "        cluster_graph = plt.scatter(embeddings[:, 0], embeddings[:, 1], #using the first 2 dimensions of embeddings\n",
    "                            c=cluster_labels, s=1, cmap=cmap)\n",
    "        \n",
    "        #creating legends\n",
    "        legend = [f'Cluster {i}' for i in range(num_clusters)]\n",
    "        plt.legend(handles=cluster_graph.legend_elements()[0], labels=legend)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Unable to plot graph, {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means clustering\n",
    "def Kmeans_clustering(all_captions:list, embeddings, num_cluster:int, csv_filepath:str=None, show_plot:bool=True):\n",
    "    \"\"\"\n",
    "    Run Kmeans clustering on dataset\n",
    "\n",
    "    Args:\n",
    "        all_captions (list): list of captions in str\n",
    "        embeddings: UMAP / sentence embeddings of all captions\n",
    "        num_cluster (int): number of clusters \n",
    "        csv_filepath (str, optional): filepath to save the csv of captions and their cluster labels, defaults to None.\n",
    "        show_plot (bool, optional): boolean to determine if the cluster graph should be shown, defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        sorted_combined_sentence_labels: list of caption (str) and their label\n",
    "    \"\"\"\n",
    "    #cluster the data\n",
    "    clusters = KMeans(n_clusters=num_cluster, random_state=0, n_init=\"auto\").fit(embeddings)\n",
    "    \n",
    "    #retrieve labels for each caption \n",
    "    cluster_labels = clusters.labels_ #list of labels for each caption\n",
    "\n",
    "    #merge the labels to the caption and sort it by labels\n",
    "    combined_sentence_labels = list(zip(all_captions, cluster_labels))\n",
    "    sorted_combined_sentence_labels = sorted(combined_sentence_labels, key=lambda x: x[1])\n",
    "\n",
    "    #save to csv if filepath is given\n",
    "    if csv_filepath != None:\n",
    "        caption_df = pd.DataFrame(sorted_combined_sentence_labels, columns=['Caption', 'Cluster Label'])\n",
    "        caption_df.to_csv(csv_filepath, index=False)\n",
    "        print(f\"Saved results to {csv_filepath}\")\n",
    "\n",
    "    #plot graph if show_plot is true\n",
    "    if show_plot:\n",
    "        plot_graph(embeddings, num_cluster, cluster_labels)\n",
    "\n",
    "    return sorted_combined_sentence_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDBScan clustering\n",
    "def HDBScan_clustering(all_captions:list, \n",
    "                       embeddings, \n",
    "                       metric:str='euclidean',\n",
    "                       cluster_selection_method = 'eom',\n",
    "                       min_cluster_size:int=15,\n",
    "                       min_samples:int=None, \n",
    "                       csv_filepath:str=None, \n",
    "                       show_plot:bool=True):\n",
    "    \"\"\"\n",
    "    Run HDBScan clustering on dataset\n",
    "    Please refer to HDBScan documents for more details: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html \n",
    "\n",
    "    Args:\n",
    "        all_captions (list): list of captions in str\n",
    "        embeddings: UMAP / sentence embeddings of all captions\n",
    "        metric (str, optional): metrics used for clustering, defaults to elucidean\n",
    "        min_cluster_size (int, optional): minimum of captions per cluster, defaults to None\n",
    "        min_samples (int, optional): determines how conservative samples will be\n",
    "        csv_filepath (str, optional): filepath to save the csv of captions and their cluster labels. Defaults to None.\n",
    "        show_plot (bool, optional): boolean to determine if the cluster graph should be shown. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        sorted_combined_sentence_labels: list of caption (str) and their label\n",
    "    \"\"\"    \n",
    "\n",
    "    #cluster the data\n",
    "    clusters = hdbscan.HDBSCAN(metric=metric,\n",
    "            cluster_selection_method=cluster_selection_method,\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples).fit(embeddings)\n",
    "    \n",
    "    #retrieve labels for each caption \n",
    "    cluster_labels = clusters.labels_ #list of labels for each caption\n",
    "\n",
    "    #merge the labels to the caption and sort it by labels\n",
    "    combined_sentence_labels = list(zip(all_captions, cluster_labels))\n",
    "    sorted_combined_sentence_labels = sorted(combined_sentence_labels, key=lambda x: x[1])\n",
    "\n",
    "    #save to csv if filepath is given\n",
    "    if csv_filepath != None:\n",
    "        caption_df = pd.DataFrame(sorted_combined_sentence_labels, columns=['Caption', 'Cluster Label'])\n",
    "        caption_df.to_csv(csv_filepath, index=False)\n",
    "        print(f\"Saved results to {csv_filepath}\")\n",
    "\n",
    "    #plot graph if show_plot is true\n",
    "    if show_plot:\n",
    "        plot_graph(embeddings, len(cluster_labels), cluster_labels)\n",
    "\n",
    "    return sorted_combined_sentence_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_kmeans = Kmeans_clustering(\n",
    "    blip['image_caption'].to_list(),\n",
    "    blip_umap_embeddings,\n",
    "    12,\n",
    "    '../blip_kmeans.csv',\n",
    "    True\n",
    ")\n",
    "\n",
    "blip_hdbscan = HDBScan_clustering(\n",
    "    all_captions=blip['image_caption'],\n",
    "    embeddings=blip_umap_embeddings,\n",
    "    csv_filepath='../blip_umap.csv',\n",
    "    show_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos_kmeans = Kmeans_clustering(\n",
    "    kosmos['image_caption'].to_list(),\n",
    "    kosmos_umap_embeddings,\n",
    "    12,\n",
    "    '../kosmos_kmeans.csv',\n",
    "    True\n",
    ")\n",
    "\n",
    "kosmos_hdbscan = HDBScan_clustering(\n",
    "    all_captions=kosmos['image_caption'],\n",
    "    embeddings=kosmos_umap_embeddings,\n",
    "    csv_filepath='../kosmos_umap.csv',\n",
    "    show_plot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
